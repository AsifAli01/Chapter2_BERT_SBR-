{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oCs70hrk3Bn"
      },
      "source": [
        "# Independent SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l_hfSHe0bPT3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "a9iXWpG2bBoj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b52e2b86-56e0-462d-de67-2c304c300b9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8kQFusSbssw"
      },
      "outputs": [],
      "source": [
        "# # Load the dataset\n",
        "# df = pd.read_csv('/content/drive/MyDrive/Sir Qasim Project/dataset.csv')\n",
        "# df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxBGZ0MOmOl8"
      },
      "outputs": [],
      "source": [
        "# df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5H0XjhxEzBtI"
      },
      "outputs": [],
      "source": [
        "# df = df.head(50000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJebcY5fjuJG"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# # creating instance of labelencoder\n",
        "# labelencoder = LabelEncoder()\n",
        "# # Assigning numerical values and storing in another column\n",
        "# df['star'] = labelencoder.fit_transform(df['star'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sY4ef33xjwzx"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "\n",
        "# sns.countplot(x='star', data=df)\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fnI_--hFq0Cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c66c2eb-4a84-456c-c58c-c027ddaed918"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeNI8gguqT2k"
      },
      "outputs": [],
      "source": [
        "# def preprocess_reviews(df, review_column, preprocessed_column):\n",
        "#     # Convert text to lowercase\n",
        "#     df[preprocessed_column] = df[review_column].str.lower()\n",
        "\n",
        "#     # Replace NaN values with an empty string\n",
        "#     df[preprocessed_column].fillna('', inplace=True)\n",
        "\n",
        "#     # Remove numbers\n",
        "#     df[preprocessed_column] = df[preprocessed_column].apply(lambda x: re.sub(r'\\d+', '', x))\n",
        "\n",
        "#     # Remove punctuation\n",
        "#     df[preprocessed_column] = df[preprocessed_column].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
        "\n",
        "#     # Tokenize text\n",
        "#     df[preprocessed_column] = df[preprocessed_column].apply(word_tokenize)\n",
        "\n",
        "#     # Remove stopwords\n",
        "#     stop_words = set(stopwords.words('english'))\n",
        "#     df[preprocessed_column] = df[preprocessed_column].apply(lambda x: [word for word in x if word not in stop_words])\n",
        "\n",
        "#     # Lemmatize words\n",
        "#     lemmatizer = WordNetLemmatizer()\n",
        "#     df[preprocessed_column] = df[preprocessed_column].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
        "\n",
        "#     # Join tokens back into a string\n",
        "#     df[preprocessed_column] = df[preprocessed_column].apply(lambda x: ' '.join(x))\n",
        "\n",
        "#     return df\n",
        "\n",
        "# # Assuming 'df' is your DataFrame\n",
        "# df = preprocess_reviews(df, 'review', 'preprocessed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YW0uLavsxME"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# # # Assuming you have an updated DataFrame named 'df' with modifications\n",
        "\n",
        "# # Save the updated DataFrame to a CSV file\n",
        "# df.to_csv('/content/drive/MyDrive/Sir Qasim Project/preprocessed_df.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YKcgG5i9tH0K"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Sir Qasim Project/preprocessed_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TF2ehCG4qYhS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "64fd3d0a-a898-4c20-a922-e356c1997c2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  package_name  \\\n",
              "0      com.mantz_it.rfanalyzer   \n",
              "1      com.mantz_it.rfanalyzer   \n",
              "2      com.mantz_it.rfanalyzer   \n",
              "3      com.mantz_it.rfanalyzer   \n",
              "4      com.mantz_it.rfanalyzer   \n",
              "...                        ...   \n",
              "49995            org.xbmc.kore   \n",
              "49996            org.xbmc.kore   \n",
              "49997            org.xbmc.kore   \n",
              "49998            org.xbmc.kore   \n",
              "49999            org.xbmc.kore   \n",
              "\n",
              "                                                  review             date  \\\n",
              "0      Great app! The new version now works on my Bra...  October 12 2016   \n",
              "1      Great It's not fully optimised and has some is...   August 23 2016   \n",
              "2      Works on a Nexus 6p I'm still messing around w...   August 04 2016   \n",
              "3      The bandwidth seemed to be limited to maximum ...     July 25 2016   \n",
              "4      Works well with my Hackrf Hopefully new update...     July 22 2016   \n",
              "...                                                  ...              ...   \n",
              "49995  The app was a lot better than I thought but .....    April 05 2017   \n",
              "49996  Surpasses all expectations! I'm in like flint ...    April 05 2017   \n",
              "49997  Crap will not connect and it's not telling me ...    April 05 2017   \n",
              "49998  This is a great app. I use it all the time. I ...    April 05 2017   \n",
              "49999  It stopped working with kodi 17 before that I ...    April 08 2017   \n",
              "\n",
              "       star                                       preprocessed  \n",
              "0         3  great app new version work bravia android tv g...  \n",
              "1         3  great fully optimised issue crashing still nic...  \n",
              "2         4  work nexus p im still messing around hackrf wo...  \n",
              "3         2  bandwidth seemed limited maximum mhz tried inc...  \n",
              "4         4  work well hackrf hopefully new update arrive e...  \n",
              "...     ...                                                ...  \n",
              "49995     2  app lot better thought could use couple extra ...  \n",
              "49996     4    surpasses expectation im like flint outstanding  \n",
              "49997     0                               crap connect telling  \n",
              "49998     4  great app use time two suggestion could add fa...  \n",
              "49999     3             stopped working kodi loved idea update  \n",
              "\n",
              "[50000 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-181180fe-82ac-4547-8756-f5786c6e5a27\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>package_name</th>\n",
              "      <th>review</th>\n",
              "      <th>date</th>\n",
              "      <th>star</th>\n",
              "      <th>preprocessed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>com.mantz_it.rfanalyzer</td>\n",
              "      <td>Great app! The new version now works on my Bra...</td>\n",
              "      <td>October 12 2016</td>\n",
              "      <td>3</td>\n",
              "      <td>great app new version work bravia android tv g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>com.mantz_it.rfanalyzer</td>\n",
              "      <td>Great It's not fully optimised and has some is...</td>\n",
              "      <td>August 23 2016</td>\n",
              "      <td>3</td>\n",
              "      <td>great fully optimised issue crashing still nic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>com.mantz_it.rfanalyzer</td>\n",
              "      <td>Works on a Nexus 6p I'm still messing around w...</td>\n",
              "      <td>August 04 2016</td>\n",
              "      <td>4</td>\n",
              "      <td>work nexus p im still messing around hackrf wo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>com.mantz_it.rfanalyzer</td>\n",
              "      <td>The bandwidth seemed to be limited to maximum ...</td>\n",
              "      <td>July 25 2016</td>\n",
              "      <td>2</td>\n",
              "      <td>bandwidth seemed limited maximum mhz tried inc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>com.mantz_it.rfanalyzer</td>\n",
              "      <td>Works well with my Hackrf Hopefully new update...</td>\n",
              "      <td>July 22 2016</td>\n",
              "      <td>4</td>\n",
              "      <td>work well hackrf hopefully new update arrive e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>org.xbmc.kore</td>\n",
              "      <td>The app was a lot better than I thought but .....</td>\n",
              "      <td>April 05 2017</td>\n",
              "      <td>2</td>\n",
              "      <td>app lot better thought could use couple extra ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>org.xbmc.kore</td>\n",
              "      <td>Surpasses all expectations! I'm in like flint ...</td>\n",
              "      <td>April 05 2017</td>\n",
              "      <td>4</td>\n",
              "      <td>surpasses expectation im like flint outstanding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>org.xbmc.kore</td>\n",
              "      <td>Crap will not connect and it's not telling me ...</td>\n",
              "      <td>April 05 2017</td>\n",
              "      <td>0</td>\n",
              "      <td>crap connect telling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>org.xbmc.kore</td>\n",
              "      <td>This is a great app. I use it all the time. I ...</td>\n",
              "      <td>April 05 2017</td>\n",
              "      <td>4</td>\n",
              "      <td>great app use time two suggestion could add fa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>org.xbmc.kore</td>\n",
              "      <td>It stopped working with kodi 17 before that I ...</td>\n",
              "      <td>April 08 2017</td>\n",
              "      <td>3</td>\n",
              "      <td>stopped working kodi loved idea update</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-181180fe-82ac-4547-8756-f5786c6e5a27')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-8a5c4478-0886-4e53-b4e6-10e67b0e2c9b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8a5c4478-0886-4e53-b4e6-10e67b0e2c9b')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-8a5c4478-0886-4e53-b4e6-10e67b0e2c9b button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-181180fe-82ac-4547-8756-f5786c6e5a27 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-181180fe-82ac-4547-8756-f5786c6e5a27');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlCnYqTr9E-8"
      },
      "outputs": [],
      "source": [
        "# # Preprocess the text data\n",
        "# # text_data = df['preprocessed']  # Replace 'text_column' with the name of the column containing the text data\n",
        "# text_data = df['review']  # Replace 'text_column' with the name of the column containing the text data\n",
        "# vectorizer = CountVectorizer()\n",
        "# X = vectorizer.fit_transform(text_data)\n",
        "\n",
        "# # Split the dataset into features (X) and labels (y)\n",
        "# y = df['star']  # Replace 'target_column' with the actual name of your target column\n",
        "\n",
        "# # Split the data into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # Adjust the test_size and random_state as desired\n",
        "\n",
        "# # Create an SVM classifier\n",
        "# classifier = SVC(kernel='linear')\n",
        "\n",
        "# # Train the classifier on the training data\n",
        "# classifier.fit(X_train, y_train)\n",
        "\n",
        "# # Make predictions on the test data\n",
        "# y_pred = classifier.predict(X_test)\n",
        "\n",
        "# # Evaluate the accuracy of the classifier\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "# print(f\"Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cM5tF6bGHQDw"
      },
      "outputs": [],
      "source": [
        "# # Print classification report and confusion matrix\n",
        "# print(classification_report(y_test, y_pred))\n",
        "\n",
        "# # Calculate and print accuracy, precision, recall, and f1-score\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "# precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
        "# print(\"Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1-score: {:.4f}\".format(accuracy, precision, recall, f1_score))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUyxj4Y9lMyp"
      },
      "source": [
        "# M/DL Models using Bert Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IFb6bh0VHhtA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65492f08-f5bc-4ced-d19f-acd310c94abb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QQKmo-9GvwoG"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sAWRGo9oxQw_"
      },
      "outputs": [],
      "source": [
        "\n",
        "# from transformers import BertTokenizer, BertModel\n",
        "# from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pYFa4c99xeI9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856,
          "referenced_widgets": [
            "2199bd3714de4ba389c6f3bd7724af2b",
            "1250d5511d5f413290506ad4a1a69425",
            "f6ae444e311044b390f3a0a8afc84b5e",
            "f4314088bad643b693af5078ad81658b",
            "60a19c2b3bb8445e812195b0beea257f",
            "e485998712ee4c34a5d3f04285709080",
            "115e1e33b5394f19a08701d99005458a",
            "a1e25cd2d84540ed967834f9ef54bef8",
            "50c1d227af9c4bf0b547853765946f30",
            "adddd57bf9f2456f8b8adfb29219fdee",
            "397fb414396940af93940478e77336fd",
            "37799b15c4e34c04bbe60df2ccb429d7",
            "84ff9b9d2f024ffdbf142905ebbbf5a6",
            "c96aecdf9d1b466aaf8cad1661465c71",
            "fd63dd951a2d4a91b13a6da9f92a4cc4",
            "bca3a777a6cb4f49a3b2d779c1df5342",
            "107997c5cdb94b1cad9c8e2c2960328b",
            "40425cd491834bf794a47d7a7d3c9b32",
            "694c0046e0a94d5fbe02103589331598",
            "9e79052d5612436d9a7ae657c8438402",
            "230a0eaaaffa45a8a428cbbaa66a3b52",
            "7094f2613f804536961634e0cc44f3d9",
            "3ee39823560c4f4fbb520d3e7d24f678",
            "407b30f5f1e842039ae7a2cbc8befe4e",
            "e52d3b623c2e4715ae00532b9d3b2ee7",
            "1ed683c18f584d0e9ac0f7f2ab6581a1",
            "e10f7e9234de45339b620ba592476fde",
            "90bf44e21b074e9a8bb586062978e5fb",
            "b7f9e6d19dba4064b598b7c2a6994b40",
            "e374d2af4f624551b27b4982d628f2a4",
            "25005957e87e4debaed621767fbc28f0",
            "a54be4a586254a959299d7aa9968add5",
            "fe0e8ef446fb4bc98ea1ca3404a987b9",
            "8bb1be2cf8294c20b3e40824349923bd",
            "395ae5003b3e46af8535587daaa66e01",
            "7ebba1993ab3442fb375342cccc37ab2",
            "0a8d243be2d24038b49d54ebdc9cdbbc",
            "7a23a146e73e4b3aad74ba65fbbc539e",
            "04e2abfdd0e849dba131bdab5c581c58",
            "71704f87a8d54ec6a8fad42028c437af",
            "ed82d2a690ed4f9ea800beaa574d8a3d",
            "cd2ecd6bf48f4a3498af1ade7cdfc904",
            "9c26db928f4345ffa09d6e8fa8a8512b",
            "09ed9f8364d44d69b6c677e90ce4e286"
          ]
        },
        "outputId": "71180f95-64e6-428d-9f54-bd66a19fd76b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2199bd3714de4ba389c6f3bd7724af2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37799b15c4e34c04bbe60df2ccb429d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ee39823560c4f4fbb520d3e7d24f678"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bb1be2cf8294c20b3e40824349923bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# # Load BERT model and tokenizer\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "# model = BertModel.from_pretrained('bert-base-uncased')\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2dbJc91xhlU"
      },
      "outputs": [],
      "source": [
        "# # Define dataset class\n",
        "# class MyDataset(Dataset):\n",
        "#     def __init__(self, texts):\n",
        "#         self.texts = texts\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.texts)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         text = self.texts[idx]\n",
        "#         return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEszPAGt7Mgk"
      },
      "outputs": [],
      "source": [
        "# def my_collate_fn(batch):\n",
        "#     return [' '.join(sample) for sample in batch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gH2DyhVywrCg",
        "outputId": "0fa005d1-13ab-4ca9-8e49-5ae32d5dd181"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n",
            "batch \n"
          ]
        }
      ],
      "source": [
        "# # Define batch size and create data loader\n",
        "# batch_size = 64\n",
        "# dataset = MyDataset(df['review'])\n",
        "# dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=4, collate_fn=my_collate_fn)\n",
        "\n",
        "\n",
        "# # Generate embeddings for each batch\n",
        "# embeddings = []\n",
        "# model.eval()\n",
        "# i = 1\n",
        "# with torch.no_grad():\n",
        "#     for batch in dataloader:\n",
        "#         # Tokenize batch\n",
        "#         inputs = tokenizer(batch, padding=True, truncation=True, return_tensors='pt')\n",
        "#         inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "#         # Generate embeddings\n",
        "#         print(\"batch \")\n",
        "#         outputs = model(**inputs)\n",
        "#         last_hidden_states = outputs.last_hidden_state\n",
        "#         mean_pooling = torch.mean(last_hidden_states, dim=1)\n",
        "#         embeddings.append(mean_pooling.cpu())\n",
        "\n",
        "# # Concatenate embeddings from each batch\n",
        "# embeddings = torch.cat(embeddings, dim=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axsS1auPe7XS"
      },
      "outputs": [],
      "source": [
        "# import pickle\n",
        "# with open(\"/content/drive/MyDrive/pp_df_embeddings_.pickle\", \"wb\") as scores:\n",
        "#     pickle.dump(embeddings, scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gqZpB8NUfPbs"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"/content/drive/MyDrive/pp_df_embeddings_.pickle\", \"rb\") as scores:\n",
        "   embeddings = pickle.load(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WsuFGbQ1PsoB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f6b5ae7-c641-4ec4-a818-b52194d3369b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDp9msGwO8N6"
      },
      "outputs": [],
      "source": [
        "# from sklearn.svm import SVC\n",
        "\n",
        "# # Split the data into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(embeddings, df['star'], test_size=0.20, random_state=42)\n",
        "\n",
        "# # Create an SVM model and fit it to the training data\n",
        "# svm_model = SVC()\n",
        "# svm_model.fit(X_train, y_train)\n",
        "\n",
        "# # Predict on test data\n",
        "# y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# # Print classification report and confusion matrix\n",
        "# print(classification_report(y_test, y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rDwXiUSPboQ"
      },
      "source": [
        "# Multinomial Naive Bays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asSM0FJ8Oeh1"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.naive_bayes import MultinomialNB\n",
        "# from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# # Split the data into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(embeddings, df['star'], test_size=0.20, random_state=42)\n",
        "\n",
        "# # Binning the embeddings\n",
        "# threshold = 0.5\n",
        "# X_train_bin = np.where(X_train > threshold, 1, 0)\n",
        "# X_test_bin = np.where(X_test > threshold, 1, 0)\n",
        "\n",
        "# # Train the MNB model\n",
        "# mnb = MultinomialNB()\n",
        "# mnb.fit(X_train_bin, y_train)\n",
        "\n",
        "# # Predict on test data\n",
        "# y_pred = mnb.predict(X_test_bin)\n",
        "\n",
        "# # Print classification report and accuracy score\n",
        "# print(classification_report(y_test, y_pred))\n",
        "# print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# # Calculate and print accuracy, precision, recall, and f1-score\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "# precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
        "# print(\"Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1-score: {:.4f}\".format(accuracy, precision, recall, f1_score))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Calculate and print accuracy, precision, recall, and f1-score\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "# precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
        "# print(\"Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1-score: {:.4f}\".format(accuracy, precision, recall, f1_score))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8GMdsteQiQM",
        "outputId": "40a59f63-bc84-4c2f-f905-974038990efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5510, Precision: 0.3914, Recall: 0.5510, F1-score: 0.4093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-KtaTyGPeMr"
      },
      "source": [
        "# Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_VIsaj3M7tw"
      },
      "outputs": [],
      "source": [
        "# from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# # Split the data into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(embeddings, df['star'], test_size=0.20, random_state=42)\n",
        "\n",
        "# # Create a Logistic Regression model and fit it to the training data\n",
        "# logreg_model = LogisticRegression()\n",
        "# logreg_model.fit(X_train, y_train)\n",
        "\n",
        "# # Predict on test data\n",
        "# y_pred = logreg_model.predict(X_test)\n",
        "\n",
        "# # Print classification report and confusion matrix\n",
        "# print(classification_report(y_test, y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Calculate and print accuracy, precision, recall, and f1-score\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "# precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
        "# print(\"Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1-score: {:.4f}\".format(accuracy, precision, recall, f1_score))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-po3ow0RSDV",
        "outputId": "70c2170c-4735-4e7c-fc50-0ea3209cec41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5694, Precision: 0.5224, Recall: 0.5694, F1-score: 0.4707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ni-GUptP6RE"
      },
      "source": [
        "# Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xom8CJQyP243",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eebf0191-79b1-402c-b7e4-61e9e540c733"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.15      0.23      1554\n",
            "           1       0.17      0.00      0.00       589\n",
            "           2       0.23      0.02      0.03       954\n",
            "           3       0.23      0.04      0.07      1549\n",
            "           4       0.56      0.97      0.71      5354\n",
            "\n",
            "    accuracy                           0.55     10000\n",
            "   macro avg       0.34      0.23      0.21     10000\n",
            "weighted avg       0.45      0.55      0.43     10000\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.15      0.23      1554\n",
            "           1       0.17      0.00      0.00       589\n",
            "           2       0.23      0.02      0.03       954\n",
            "           3       0.23      0.04      0.07      1549\n",
            "           4       0.56      0.97      0.71      5354\n",
            "\n",
            "    accuracy                           0.55     10000\n",
            "   macro avg       0.34      0.23      0.21     10000\n",
            "weighted avg       0.45      0.55      0.43     10000\n",
            "\n",
            "Accuracy: 0.5482, Precision: 0.4466, Recall: 0.5482, F1-score: 0.4300\n"
          ]
        }
      ],
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "\n",
        "# # Split the data into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(embeddings, df['star'], test_size=0.20, random_state=42)\n",
        "\n",
        "# # Create a Random Forest model and fit it to the training data\n",
        "# rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "# rf_model.fit(X_train, y_train)\n",
        "\n",
        "# # Predict on test data\n",
        "# y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# # Print classification report and confusion matrix\n",
        "# print(classification_report(y_test, y_pred))\n",
        "\n",
        "# # Calculate and print accuracy\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# # Calculate and print accuracy, precision, recall, and f1-score\n",
        "# precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
        "# print(\"Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1-score: {:.4f}\".format(accuracy, precision, recall, f1_score))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, precision_recall_fscore_support, accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "hf5zdRAMk0WH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GradientBoostingClassifier"
      ],
      "metadata": {
        "id": "qYSi36dMsnvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # # Split the data into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(embeddings, df['star'], test_size=0.20, random_state=42)\n",
        "\n",
        "# # Define the boosting ensemble model\n",
        "# gb_model = GradientBoostingClassifier(n_estimators=10, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "\n",
        "# # Train the model on the training set\n",
        "# gb_model.fit(X_train, y_train)\n",
        "\n",
        "# y_pred_prob_gb = gb_model.predict_proba(X_test.reshape((X_test.shape[0], -1)))\n",
        "# y_pred_gb = np.round(y_pred_prob_gb[:, 1]).astype('int')\n",
        "\n",
        "\n",
        "# # Print the classification report\n",
        "# print(classification_report(y_test, y_pred_gb))\n"
      ],
      "metadata": {
        "id": "xN4fLqWDsm_Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bab240e4-b8d9-43de-f594-41a5180d187b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.16      1.00      0.27      1554\n",
            "           1       0.00      0.00      0.00       589\n",
            "           2       0.00      0.00      0.00       954\n",
            "           3       0.00      0.00      0.00      1549\n",
            "           4       0.00      0.00      0.00      5354\n",
            "\n",
            "    accuracy                           0.16     10000\n",
            "   macro avg       0.03      0.20      0.05     10000\n",
            "weighted avg       0.02      0.16      0.04     10000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Calculate and print accuracy, precision, recall, and f1-score\n",
        "# print(\"GBM.....\")\n",
        "# accuracy = accuracy_score(y_test, y_pred_gb)\n",
        "# precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred_gb, average='weighted')\n",
        "# print(\"Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1-score: {:.4f}\".format(accuracy, precision, recall, f1_score))"
      ],
      "metadata": {
        "id": "tm0esL26GwZf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af162443-4b25-47c3-88dd-0089e7aebcb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GBM.....\n",
            "Accuracy: 0.1554, Precision: 0.0241, Recall: 0.1554, F1-score: 0.0418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Calculate count of each label\n",
        "# unique_labels, label_counts = np.unique(df['star'], return_counts=True)\n",
        "\n",
        "# # Print results\n",
        "# for label, count in zip(unique_labels, label_counts):\n",
        "#     print(f\"Label {label}: {count} instances\")"
      ],
      "metadata": {
        "id": "4SNsEnjx8hRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "013ae375-d569-4818-a889-fde5d07e7619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label 0: 7625 instances\n",
            "Label 1: 2995 instances\n",
            "Label 2: 4723 instances\n",
            "Label 3: 7580 instances\n",
            "Label 4: 27077 instances\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM on Ramdom Splition"
      ],
      "metadata": {
        "id": "XGZb5xrIwGfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(embeddings.numpy(), df['star'].values, test_size=0.20, random_state=42)\n",
        "\n",
        "\n",
        "# Reshape the input data\n",
        "X_train = X_train[:, np.newaxis, :]\n",
        "X_test = X_test[:, np.newaxis, :]\n",
        "\n",
        "# Convert numpy arrays to PyTorch tensors\n",
        "X_train = torch.tensor(X_train)\n",
        "X_test = torch.tensor(X_test)\n",
        "y_train = torch.tensor(y_train)\n",
        "y_test = torch.tensor(y_test)\n",
        "\n",
        "# Set the parameters for the LSTM model\n",
        "input_size = X_train.shape[2]  # Number of features in the input (embedding size)\n",
        "hidden_size = 128  # Number of LSTM units\n",
        "output_size = 5  # Number of classes (adjust this based on your actual number of classes)\n",
        "\n",
        "\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Define the LSTM model with an additional LSTM layer and dropout\n",
        "class ImprovedLSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(ImprovedLSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm1 = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.lstm2 = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm1(x, (h0, c0))\n",
        "        out, _ = self.lstm2(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Create an instance of the Improved LSTM model\n",
        "improved_model = ImprovedLSTMModel(input_size, hidden_size, output_size)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(improved_model.parameters(), lr=0.001)\n",
        "\n",
        "# Create data loaders\n",
        "train_dataset = TensorDataset(X_train, y_train.long())\n",
        "test_dataset = TensorDataset(X_test, y_test.long())\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# Train the model\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    improved_model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, targets in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = improved_model(inputs.float())\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}\")\n",
        "\n",
        "# Evaluate the improved model on the test set\n",
        "improved_model.eval()\n",
        "predictions = []\n",
        "true_labels = []\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        outputs = improved_model(inputs.float())\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        predictions.extend(predicted.tolist())\n",
        "        true_labels.extend(targets.tolist())\n",
        "\n",
        "# Convert predictions and true labels to numpy arrays\n",
        "predictions = np.array(predictions)\n",
        "true_labels = np.array(true_labels)\n",
        "\n",
        "# Calculate accuracy, precision, recall, and F1-score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = 100 * accuracy_score(true_labels, predictions)\n",
        "precision = precision_score(true_labels, predictions, average='macro')\n",
        "recall = recall_score(true_labels, predictions, average='macro')\n",
        "f1 = f1_score(true_labels, predictions, average='macro')\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}%\")\n",
        "print(f\"Precision: {precision:.5f}\")\n",
        "print(f\"Recall: {recall:.5f}\")\n",
        "print(f\"F1-score: {f1:.5f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prE0buX7pvjg",
        "outputId": "0b73fe1d-28a9-4849-dcb0-501614b6617e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 1.225508491230011\n",
            "Epoch 2/20, Loss: 1.177860736656189\n",
            "Epoch 3/20, Loss: 1.1582372699737549\n",
            "Epoch 4/20, Loss: 1.1430665369033814\n",
            "Epoch 5/20, Loss: 1.1347453414916993\n",
            "Epoch 6/20, Loss: 1.1236258922576905\n",
            "Epoch 7/20, Loss: 1.1192678330421448\n",
            "Epoch 8/20, Loss: 1.1099739939689637\n",
            "Epoch 9/20, Loss: 1.104878522014618\n",
            "Epoch 10/20, Loss: 1.0994250473976135\n",
            "Epoch 11/20, Loss: 1.0941252688407899\n",
            "Epoch 12/20, Loss: 1.0890193842887879\n",
            "Epoch 13/20, Loss: 1.0839151012420654\n",
            "Epoch 14/20, Loss: 1.0789712150573731\n",
            "Epoch 15/20, Loss: 1.0784035151481628\n",
            "Epoch 16/20, Loss: 1.0726219171524047\n",
            "Epoch 17/20, Loss: 1.0699025477409363\n",
            "Epoch 18/20, Loss: 1.0617968948364258\n",
            "Epoch 19/20, Loss: 1.0569019116401672\n",
            "Epoch 20/20, Loss: 1.0542530368804932\n",
            "Test Accuracy: 57.7900%\n",
            "Precision: 0.33612\n",
            "Recall: 0.32928\n",
            "F1-score: 0.31274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "precision = precision_score(true_labels, predictions, average='macro')\n",
        "recall = recall_score(true_labels, predictions, average='macro')\n",
        "f1 = f1_score(true_labels, predictions, average='macro')\n",
        "print(f\"accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4eBSKQorMEO",
        "outputId": "e6ba0a69-d8ad-4650-f591-755df031db7d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.5687\n",
            "Precision: 0.3827\n",
            "Recall: 0.3068\n",
            "F1-score: 0.2660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Neural Network Model"
      ],
      "metadata": {
        "id": "IloxVY1wVs8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(embeddings.numpy(), df['star'].values, test_size=0.20, random_state=42)\n"
      ],
      "metadata": {
        "id": "TTkB2NL89sL3"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert numpy arrays to PyTorch tensors\n",
        "X_train = torch.tensor(X_train)\n",
        "X_test = torch.tensor(X_test)\n",
        "y_train = torch.tensor(y_train)\n",
        "y_test = torch.tensor(y_test)\n",
        "\n",
        "# Define the Neural Network model\n",
        "class SimpleNNModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleNNModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# Set the parameters for the neural network model\n",
        "input_size = X_train.shape[1]  # Number of features in the input (embedding size)\n",
        "hidden_size = 128  # Number of units in the hidden layer\n",
        "output_size = 10  # Number of classes (adjust this based on your actual number of classes)\n",
        "\n",
        "# Create an instance of the Neural Network model\n",
        "model = SimpleNNModel(input_size, hidden_size, output_size)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Create data loaders\n",
        "train_dataset = TensorDataset(X_train, y_train.long())\n",
        "test_dataset = TensorDataset(X_test, y_test.long())\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# Train the model\n",
        "epochs = 20\n",
        "learning_rate = 0.001\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, targets in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs.float())\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "model.eval()\n",
        "predictions = []\n",
        "true_labels = []\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        outputs = model(inputs.float())\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        predictions.extend(predicted.tolist())\n",
        "        true_labels.extend(targets.tolist())\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "# Convert predictions and true labels to numpy arrays\n",
        "predictions = np.array(predictions)\n",
        "true_labels = np.array(true_labels)\n",
        "\n",
        "# Calculate accuracy, precision, recall, and F1-score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "precision = precision_score(true_labels, predictions, average='macro')\n",
        "recall = recall_score(true_labels, predictions, average='macro')\n",
        "f1 = f1_score(true_labels, predictions, average='macro')\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "print(f\"Precision: {precision:.5f}\")\n",
        "print(f\"Recall: {recall:.5f}\")\n",
        "print(f\"F1-score: {f1:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5hg2fAdshXI",
        "outputId": "0c4e67a7-2ea3-4b82-b8e8-b41b2f18709d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 1.238322433567047\n",
            "Epoch 2/20, Loss: 1.186418128967285\n",
            "Epoch 3/20, Loss: 1.1696270130157471\n",
            "Epoch 4/20, Loss: 1.1557938105583192\n",
            "Epoch 5/20, Loss: 1.1477766967773437\n",
            "Epoch 6/20, Loss: 1.1391760805130005\n",
            "Epoch 7/20, Loss: 1.130601531124115\n",
            "Epoch 8/20, Loss: 1.1260968821525574\n",
            "Epoch 9/20, Loss: 1.1232175872802734\n",
            "Epoch 10/20, Loss: 1.1176559824943542\n",
            "Epoch 11/20, Loss: 1.11250364112854\n",
            "Epoch 12/20, Loss: 1.1099407731056214\n",
            "Epoch 13/20, Loss: 1.1051550415039062\n",
            "Epoch 14/20, Loss: 1.10250625\n",
            "Epoch 15/20, Loss: 1.0984811698913575\n",
            "Epoch 16/20, Loss: 1.0945642557144164\n",
            "Epoch 17/20, Loss: 1.0941097137451172\n",
            "Epoch 18/20, Loss: 1.0933427268981935\n",
            "Epoch 19/20, Loss: 1.084920907497406\n",
            "Epoch 20/20, Loss: 1.0863941347122192\n",
            "Test Accuracy: 57.88%\n",
            "Precision: 0.39070\n",
            "Recall: 0.28931\n",
            "F1-score: 0.28271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simle CNN"
      ],
      "metadata": {
        "id": "Xsds8EmCCzC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(embeddings.numpy(), df['star'].values, test_size=0.20, random_state=42)"
      ],
      "metadata": {
        "id": "n_wR7R9kvf14"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming you have already imported the required libraries and created 'X_train', 'X_test', 'y_train', and 'y_test'.\n",
        "\n",
        "# Convert numpy arrays to PyTorch tensors\n",
        "X_train = torch.tensor(X_train)\n",
        "X_test = torch.tensor(X_test)\n",
        "y_train = torch.tensor(y_train)\n",
        "y_test = torch.tensor(y_test)\n",
        "\n",
        "# Define the CNN model\n",
        "class AdvancedCNNModel(nn.Module):\n",
        "    def __init__(self, input_channels, num_classes):\n",
        "        super(AdvancedCNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool1d(kernel_size=2)\n",
        "        self.fc1 = nn.Linear(256 * (X_train.shape[-1] // 8), 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# Set the parameters for the CNN model\n",
        "input_channels = 1  # Number of channels in the input data (since it's one-dimensional)\n",
        "num_classes = len(set(y_train.tolist()))  # Number of classes (adjust based on your actual number of classes)\n",
        "\n",
        "# Create an instance of the Advanced CNN model\n",
        "model = AdvancedCNNModel(input_channels, num_classes)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Create data loaders\n",
        "train_dataset = TensorDataset(X_train.unsqueeze(1), y_train.long())  # Add an extra dimension for the channel\n",
        "test_dataset = TensorDataset(X_test.unsqueeze(1), y_test.long())\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# Train the model\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, targets in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs.float())\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "model.eval()\n",
        "predictions = []\n",
        "true_labels = []\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        outputs = model(inputs.float())\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        predictions.extend(predicted.tolist())\n",
        "        true_labels.extend(targets.tolist())\n",
        "\n",
        "# Convert predictions and true labels to numpy arrays\n",
        "predictions = np.array(predictions)\n",
        "true_labels = np.array(true_labels)\n",
        "\n",
        "# Calculate accuracy, precision, recall, and F1-score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = 100 * accuracy_score(true_labels, predictions)\n",
        "precision = precision_score(true_labels, predictions, average='macro')\n",
        "recall = recall_score(true_labels, predictions, average='macro')\n",
        "f1 = f1_score(true_labels, predictions, average='macro')\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "print(f\"Precision: {precision:.5f}\")\n",
        "print(f\"Recall: {recall:.5f}\")\n",
        "print(f\"F1-score: {f1:.5f}\")\n"
      ],
      "metadata": {
        "id": "O7dm6eomvyOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBClassifier"
      ],
      "metadata": {
        "id": "KqWdLaQKtymN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tjj85-MwLhD",
        "outputId": "f7b9bd5e-e771-41b1-9906-f8406390b95f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (1.7.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.10.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Split data into training and test sets (assuming 'embeddings' is a NumPy array)\n",
        "X_train, X_test, y_train, y_test = train_test_split(embeddings, df['star'], test_size=0.20, random_state=42)\n",
        "\n",
        "# Create the XGBoost model\n",
        "model = xgb.XGBClassifier(\n",
        "    objective='multi:softmax',  # Multiclass classification\n",
        "    num_class=len(set(y_train)),  # Number of classes\n",
        "    learning_rate=0.1,\n",
        "    n_estimators=100,  # Number of trees (boosting rounds)\n",
        "    max_depth=5,  # Maximum tree depth\n",
        "    subsample=0.8,  # Subsample ratio of the training instances\n",
        "    colsample_bytree=0.8,  # Subsample ratio of features for building each tree\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = 100 * accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "print(f\"Precision: {precision:.5f}\")\n",
        "print(f\"Recall: {recall:.5f}\")\n",
        "print(f\"F1-score: {f1:.5f}\")\n"
      ],
      "metadata": {
        "id": "JwzlYbo6wHkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DT"
      ],
      "metadata": {
        "id": "BVdarFl_56jZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Split data into training and test sets (assuming 'embeddings' is a NumPy array)\n",
        "X_train, X_test, y_train, y_test = train_test_split(embeddings, df['star'], test_size=0.20, random_state=42)\n",
        "# Create a Decision Tree classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy, precision, recall, and F1-score\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions, average='macro')\n",
        "recall = recall_score(y_test, predictions, average='macro')\n",
        "f1 = f1_score(y_test, predictions, average='macro')\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwEHwZkj59Kl",
        "outputId": "9e2b8051-7e3c-4237-803e-0b95522ae9b2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.4126\n",
            "Precision: 0.2588\n",
            "Recall: 0.2597\n",
            "F1-score: 0.2592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN"
      ],
      "metadata": {
        "id": "G6bCzgcDuRh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vN-dcV479iFn",
        "outputId": "822bd95f-f320-4f37-e9e1-1b926cf50259"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'embeddings' is a torch.Tensor with shape [50000, 768]\n",
        "X_train, X_test, y_train, y_test = train_test_split(embeddings.numpy(), df['star'], test_size=0.20, random_state=42)\n",
        "\n",
        "# Convert numpy arrays to PyTorch tensors using the recommended approach\n",
        "X_train = torch.tensor(X_train).clone().detach()\n",
        "X_test = torch.tensor(X_test).clone().detach()\n",
        "y_train = torch.tensor(y_train.values).clone().detach()  # Convert to tensor and use .values to get the underlying numpy array\n",
        "y_test = torch.tensor(y_test.values).clone().detach()  # Convert to tensor and use .values to get the underlying numpy array\n",
        "\n",
        "# Set the parameters for the RNN model\n",
        "input_size = X_train.shape[1]  # Number of features in the input (embedding size)\n",
        "hidden_size = 128  # Number of units in the hidden layer\n",
        "output_size = len(set(y_train.tolist()))  # Number of classes (adjust based on your actual number of classes)\n",
        "\n",
        "# Define the RNN model\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.rnn(x[:, np.newaxis, :], h0)  # Add a new dimension to the input tensor\n",
        "        out = self.fc(out[:, -1, :])  # Take the last time step's output for classification\n",
        "        return out\n",
        "\n",
        "# Create an instance of the RNN model\n",
        "rnn_model = RNNModel(input_size, hidden_size, output_size)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(rnn_model.parameters(), lr=0.001)\n",
        "\n",
        "# Create data loaders\n",
        "train_dataset = TensorDataset(X_train, y_train.long())\n",
        "test_dataset = TensorDataset(X_test, y_test.long())\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# Train the model\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    rnn_model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, targets in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = rnn_model(inputs.float())\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}\")\n",
        "\n",
        "# Evaluate the RNN model on the test set\n",
        "rnn_model.eval()\n",
        "predictions = []\n",
        "true_labels = []\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        outputs = rnn_model(inputs.float())\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        predictions.extend(predicted.tolist())\n",
        "        true_labels.extend(targets.tolist())\n",
        "\n",
        "# Convert predictions and true labels to numpy arrays\n",
        "predictions = np.array(predictions)\n",
        "true_labels = np.array(true_labels)\n",
        "\n",
        "# Calculate accuracy, precision, recall, and F1-score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = 100 * accuracy_score(true_labels, predictions)\n",
        "precision = precision_score(true_labels, predictions, average='macro')\n",
        "recall = recall_score(true_labels, predictions, average='macro')\n",
        "f1 = f1_score(true_labels, predictions, average='macro')\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}%\")\n",
        "print(f\"Precision: {precision:.5f}\")\n",
        "print(f\"Recall: {recall:.5f}\")\n",
        "print(f\"F1-score: {f1:.5f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdgxVtBT-aTG",
        "outputId": "01b553df-c73e-4bbc-cee0-0af205fdfe36"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 1.215295927619934\n",
            "Epoch 2/20, Loss: 1.1788862622261047\n",
            "Epoch 3/20, Loss: 1.161038773536682\n",
            "Epoch 4/20, Loss: 1.1489220127105713\n",
            "Epoch 5/20, Loss: 1.14583547706604\n",
            "Epoch 6/20, Loss: 1.1366325310707093\n",
            "Epoch 7/20, Loss: 1.1300058047294617\n",
            "Epoch 8/20, Loss: 1.125204581642151\n",
            "Epoch 9/20, Loss: 1.118782430934906\n",
            "Epoch 10/20, Loss: 1.1158389718055726\n",
            "Epoch 11/20, Loss: 1.1119788091659546\n",
            "Epoch 12/20, Loss: 1.1053631677627564\n",
            "Epoch 13/20, Loss: 1.1039576558113098\n",
            "Epoch 14/20, Loss: 1.0998678131103516\n",
            "Epoch 15/20, Loss: 1.0992878558158874\n",
            "Epoch 16/20, Loss: 1.0898145028114319\n",
            "Epoch 17/20, Loss: 1.090225496482849\n",
            "Epoch 18/20, Loss: 1.0847076439857484\n",
            "Epoch 19/20, Loss: 1.080461592388153\n",
            "Epoch 20/20, Loss: 1.0786890522003174\n",
            "Test Accuracy: 58.5400%\n",
            "Precision: 0.36365\n",
            "Recall: 0.31149\n",
            "F1-score: 0.29898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adaboost"
      ],
      "metadata": {
        "id": "G8iaUJwGaD-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming 'embeddings' is a torch.Tensor with shape [50000, 768]\n",
        "X_train, X_test, y_train, y_test = train_test_split(embeddings.numpy(), df['star'], test_size=0.20, random_state=42)\n",
        "\n",
        "# Convert y_train and y_test to numpy arrays\n",
        "y_train = y_train.values\n",
        "y_test = y_test.values\n",
        "\n",
        "# Create an instance of DecisionTreeClassifier as the base estimator\n",
        "base_estimator = DecisionTreeClassifier(max_depth=2)\n",
        "\n",
        "# Create the AdaBoostClassifier with the base estimator\n",
        "adaboost_model = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=50, random_state=42)\n",
        "\n",
        "# Train the AdaBoost model\n",
        "adaboost_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "predictions = adaboost_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy, precision, recall, and F1-score\n",
        "accuracy = 100 * accuracy_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions, average='macro')\n",
        "recall = recall_score(y_test, predictions, average='macro')\n",
        "f1 = f1_score(y_test, predictions, average='macro')\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}%\")\n",
        "print(f\"Precision: {precision:.5f}\")\n",
        "print(f\"Recall: {recall:.5f}\")\n",
        "print(f\"F1-score: {f1:.5f}\")\n"
      ],
      "metadata": {
        "id": "mym8PcLUZ6_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f27e7724-f823-4431-84fd-25e0f7abe766"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 53.9300%\n",
            "Precision: 0.28563\n",
            "Recall: 0.24308\n",
            "F1-score: 0.21762\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2199bd3714de4ba389c6f3bd7724af2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1250d5511d5f413290506ad4a1a69425",
              "IPY_MODEL_f6ae444e311044b390f3a0a8afc84b5e",
              "IPY_MODEL_f4314088bad643b693af5078ad81658b"
            ],
            "layout": "IPY_MODEL_60a19c2b3bb8445e812195b0beea257f"
          }
        },
        "1250d5511d5f413290506ad4a1a69425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e485998712ee4c34a5d3f04285709080",
            "placeholder": "​",
            "style": "IPY_MODEL_115e1e33b5394f19a08701d99005458a",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "f6ae444e311044b390f3a0a8afc84b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1e25cd2d84540ed967834f9ef54bef8",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50c1d227af9c4bf0b547853765946f30",
            "value": 231508
          }
        },
        "f4314088bad643b693af5078ad81658b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adddd57bf9f2456f8b8adfb29219fdee",
            "placeholder": "​",
            "style": "IPY_MODEL_397fb414396940af93940478e77336fd",
            "value": " 232k/232k [00:00&lt;00:00, 4.98MB/s]"
          }
        },
        "60a19c2b3bb8445e812195b0beea257f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e485998712ee4c34a5d3f04285709080": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "115e1e33b5394f19a08701d99005458a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1e25cd2d84540ed967834f9ef54bef8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50c1d227af9c4bf0b547853765946f30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "adddd57bf9f2456f8b8adfb29219fdee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "397fb414396940af93940478e77336fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37799b15c4e34c04bbe60df2ccb429d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84ff9b9d2f024ffdbf142905ebbbf5a6",
              "IPY_MODEL_c96aecdf9d1b466aaf8cad1661465c71",
              "IPY_MODEL_fd63dd951a2d4a91b13a6da9f92a4cc4"
            ],
            "layout": "IPY_MODEL_bca3a777a6cb4f49a3b2d779c1df5342"
          }
        },
        "84ff9b9d2f024ffdbf142905ebbbf5a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_107997c5cdb94b1cad9c8e2c2960328b",
            "placeholder": "​",
            "style": "IPY_MODEL_40425cd491834bf794a47d7a7d3c9b32",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "c96aecdf9d1b466aaf8cad1661465c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_694c0046e0a94d5fbe02103589331598",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e79052d5612436d9a7ae657c8438402",
            "value": 28
          }
        },
        "fd63dd951a2d4a91b13a6da9f92a4cc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_230a0eaaaffa45a8a428cbbaa66a3b52",
            "placeholder": "​",
            "style": "IPY_MODEL_7094f2613f804536961634e0cc44f3d9",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.01kB/s]"
          }
        },
        "bca3a777a6cb4f49a3b2d779c1df5342": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "107997c5cdb94b1cad9c8e2c2960328b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40425cd491834bf794a47d7a7d3c9b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "694c0046e0a94d5fbe02103589331598": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e79052d5612436d9a7ae657c8438402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "230a0eaaaffa45a8a428cbbaa66a3b52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7094f2613f804536961634e0cc44f3d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ee39823560c4f4fbb520d3e7d24f678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_407b30f5f1e842039ae7a2cbc8befe4e",
              "IPY_MODEL_e52d3b623c2e4715ae00532b9d3b2ee7",
              "IPY_MODEL_1ed683c18f584d0e9ac0f7f2ab6581a1"
            ],
            "layout": "IPY_MODEL_e10f7e9234de45339b620ba592476fde"
          }
        },
        "407b30f5f1e842039ae7a2cbc8befe4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90bf44e21b074e9a8bb586062978e5fb",
            "placeholder": "​",
            "style": "IPY_MODEL_b7f9e6d19dba4064b598b7c2a6994b40",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "e52d3b623c2e4715ae00532b9d3b2ee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e374d2af4f624551b27b4982d628f2a4",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25005957e87e4debaed621767fbc28f0",
            "value": 570
          }
        },
        "1ed683c18f584d0e9ac0f7f2ab6581a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a54be4a586254a959299d7aa9968add5",
            "placeholder": "​",
            "style": "IPY_MODEL_fe0e8ef446fb4bc98ea1ca3404a987b9",
            "value": " 570/570 [00:00&lt;00:00, 22.1kB/s]"
          }
        },
        "e10f7e9234de45339b620ba592476fde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90bf44e21b074e9a8bb586062978e5fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7f9e6d19dba4064b598b7c2a6994b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e374d2af4f624551b27b4982d628f2a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25005957e87e4debaed621767fbc28f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a54be4a586254a959299d7aa9968add5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe0e8ef446fb4bc98ea1ca3404a987b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bb1be2cf8294c20b3e40824349923bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_395ae5003b3e46af8535587daaa66e01",
              "IPY_MODEL_7ebba1993ab3442fb375342cccc37ab2",
              "IPY_MODEL_0a8d243be2d24038b49d54ebdc9cdbbc"
            ],
            "layout": "IPY_MODEL_7a23a146e73e4b3aad74ba65fbbc539e"
          }
        },
        "395ae5003b3e46af8535587daaa66e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04e2abfdd0e849dba131bdab5c581c58",
            "placeholder": "​",
            "style": "IPY_MODEL_71704f87a8d54ec6a8fad42028c437af",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "7ebba1993ab3442fb375342cccc37ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed82d2a690ed4f9ea800beaa574d8a3d",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd2ecd6bf48f4a3498af1ade7cdfc904",
            "value": 440449768
          }
        },
        "0a8d243be2d24038b49d54ebdc9cdbbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c26db928f4345ffa09d6e8fa8a8512b",
            "placeholder": "​",
            "style": "IPY_MODEL_09ed9f8364d44d69b6c677e90ce4e286",
            "value": " 440M/440M [00:02&lt;00:00, 179MB/s]"
          }
        },
        "7a23a146e73e4b3aad74ba65fbbc539e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04e2abfdd0e849dba131bdab5c581c58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71704f87a8d54ec6a8fad42028c437af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed82d2a690ed4f9ea800beaa574d8a3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd2ecd6bf48f4a3498af1ade7cdfc904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c26db928f4345ffa09d6e8fa8a8512b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09ed9f8364d44d69b6c677e90ce4e286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}